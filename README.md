# AI Template Agent

A Python AI agent built with LangChain and OpenRouter that generates structured JSON templates via a WebAPI.

## Features

- ğŸ¤– **AI-Powered Template Generation** - Uses LangChain with OpenRouter for structured JSON output
- ğŸš€ **FastAPI WebAPI** - Modern async API with automatic validation
- ğŸ“š **Scalar Documentation** - Beautiful, interactive API docs at `/scalar`
- âš™ï¸ **Type-Safe Configuration** - Pydantic settings with `.env` file support

## Quick Start

### Prerequisites

- Python 3.12+
- OpenRouter API key ([get one here](https://openrouter.ai/keys))

### Installation

1. **Clone and navigate to the project**
   ```bash
   cd /path/to/AI\ POC
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -e ".[dev]"
   ```

4. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env and add your OPENROUTER_API_KEY
   ```

5. **Run the server**
   ```bash
   uvicorn src.ai_agent.main:app --reload
   ```

6. **Open API docs**
   - Navigate to http://localhost:8000/scalar

## API Endpoints

### Metadata Generation

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/metadata/generate` | Generate a template from a prompt (synchronous) |
| `POST` | `/api/v1/metadata/generate-stream` | Stream template generation with SSE (real-time) |
| `GET` | `/api/v1/health` | Health check |

### Documentation

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/scalar` | Interactive API documentation |
| `GET` | `/` | Root endpoint with docs link |

### Streaming Endpoint

The `/generate-stream` endpoint uses Server-Sent Events (SSE) for real-time generation:

```bash
curl -X POST http://localhost:8000/api/v1/metadata/generate-stream \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Create a user registration form"}' \
  --no-buffer
```

**Event Types:**
- `thinking` - Reasoning content (if model supports thinking mode)
- `content` - Generation content chunks
- `template` - Final structured template with explanation
- `error` - Error event
- `done` - Stream completed

## Project Structure

```
AI POC/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ai_agent/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py              # ğŸš€ ENTRYPOINT - FastAPI application factory
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ settings.py      # Pydantic settings with .env support
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ __init__.py      # Router exports
â”‚       â”‚   â”œâ”€â”€ routes.py        # Sync generate endpoint + health
â”‚       â”‚   â”œâ”€â”€ streaming_routes.py  # SSE streaming endpoint
â”‚       â”‚   â””â”€â”€ dependencies.py  # FastAPI dependency injection
â”‚       â”œâ”€â”€ agent/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ core.py          # TemplateAgent (sync generation)
â”‚       â”‚   â”œâ”€â”€ streaming.py     # StreamingTemplateAgent (SSE)
â”‚       â”‚   â””â”€â”€ prompts.py       # System/user prompt templates
â”‚       â””â”€â”€ schemas/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ request.py       # API request models
â”‚           â”œâ”€â”€ response.py      # Template response models
â”‚           â””â”€â”€ streaming.py     # SSE event models
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py              # Pytest fixtures
â”‚   â”œâ”€â”€ test_agent.py            # Agent unit tests
â”‚   â”œâ”€â”€ test_api.py              # API endpoint tests
â”‚   â”œâ”€â”€ test_config.py           # Configuration tests
â”‚   â””â”€â”€ test_streaming.py        # Streaming tests
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ pyproject.toml               # Project dependencies
â””â”€â”€ README.md
```

## Scripts & Commands

### Development Server

```bash
# Start with auto-reload
uvicorn src.ai_agent.main:app --reload

# Start on specific port
uvicorn src.ai_agent.main:app --reload --port 8080

# Start with debug logging
LOG_LEVEL=DEBUG uvicorn src.ai_agent.main:app --reload
```

### Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=src/ai_agent

# Run specific test file
pytest tests/test_streaming.py -v
```

### API Testing

```bash
# Health check
curl http://localhost:8000/api/v1/health

# Generate template (sync)
curl -X POST http://localhost:8000/api/v1/metadata/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Create a contact form"}'

# Generate template (streaming)
curl -X POST http://localhost:8000/api/v1/metadata/generate-stream \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Create a user registration form"}' \
  --no-buffer
```

## Configuration

All configuration is managed via environment variables (`.env` file):

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENROUTER__API_KEY` | Your OpenRouter API key | *required* |
| `OPENROUTER__BASE_URL` | OpenRouter API endpoint | `https://openrouter.ai/api/v1` |
| `OPENROUTER__MODEL` | Model to use | `openai/gpt-oss-20b:free` |
| `APP_DEBUG` | Enable debug mode | `false` |
| `LOG_LEVEL` | Logging level | `INFO` |
